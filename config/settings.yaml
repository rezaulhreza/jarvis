# Jarvis Configuration
# Secrets should be in .env file, not here!

# User Profile (customize in ~/.jarvis/config/settings.yaml)
user:
  name: ""                  # Your full name
  nickname: ""              # How Jarvis should address you (optional)
  address_user: false       # Whether Jarvis should address you by name

# Model Settings
models:
  default: "qwen3:4b"
  reasoning: "deepseek-r1:8b"
  vision: "llava"
  code: "qwen2.5-coder:7b"
  tools: "functiongemma"
  embeddings: "nomic-embed-text"

# Context Management
context:
  max_tokens: 128000
  keep_recent_messages: 10
  auto_compact: true
  summary_model: "qwen3:4b"

# Agent Behavior
agent:
  # Tool handling: "auto" (default), "native", "prompt", "off"
  tool_mode: "auto"
  # Auto-run tools for time/weather/current info when detected
  auto_tools: true
  auto_current_info: true
  auto_weather: true
  auto_time: true
  auto_calculate: true
  # Skip tool-capable loop when tools are unlikely
  fast_no_tools: true
  # Timeouts (seconds)
  timeouts:
    default: 120
    reasoning: 300

# Intent Classification (smart routing)
intent:
  enabled: true                    # Enable intent classification
  llm_enabled: false               # Use LLM for classification (slow, set true for accuracy)
  classifier_model: "fast"         # Model type when LLM enabled
  cache_ttl: 300                   # Cache similar intents for 5 minutes
  confidence_threshold: 0.7        # LLM confidence threshold
  # User can override default reasoning levels with regex patterns
  reasoning_overrides:
    "explain.*in detail": "deep"
    "quick.*answer": "fast"
    "think.*through": "deep"
    "step by step": "deep"
    "briefly": "fast"

# Reasoning Levels (model selection by complexity)
reasoning:
  # Default reasoning level when not auto-detected
  default_level: "balanced"
  levels:
    fast:
      model: "fast"                # Maps to provider's fast model (gemma-3-4b)
      max_tokens: 500
      timeout: 10
      description: "Quick responses for simple queries"
    balanced:
      model: "default"             # Maps to provider's default model (Qwen3-32B)
      max_tokens: 2000
      timeout: 30
      description: "Standard responses for most queries"
    deep:
      model: "deep"                # Maps to provider's deep model (Kimi K2.5)
      max_tokens: 8000
      timeout: 180
      enable_reflection: true      # Chain-of-thought prompting
      description: "Complex reasoning and detailed analysis"

# Memory Settings
memory:
  database: "memory/jarvis.db"
  vector_store: "knowledge/chroma_db"  # ChromaDB local path (fallback when Qdrant not configured)
  # Vector backend is auto-detected from env: QDRANT_URL + QDRANT_API_KEY → Qdrant, otherwise → ChromaDB
  rerank: true  # Enable cross-encoder reranking for better retrieval accuracy
  rerank_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"  # Reranker model (requires sentence-transformers)
  # rerank_threshold: -5.0  # Min rerank score (disabled by default - calibrate on your data first)
  relevance_threshold: 0.5  # Max cosine distance when reranker disabled (0-1, lower = stricter)
  embedding_dim: 768  # Expected embedding dimension (nomic-embed-text = 768)
  facts_file: "memory/facts.md"
  entities_file: "memory/entities.json"

# Active Persona (see config/personas/)
persona: "default"

# Integrations
integrations:
  telegram:
    enabled: false
    # Token loaded from TELEGRAM_BOT_TOKEN env var

  web_search:
    enabled: true
    # provider: "duckduckgo"
    provider: "brave"

  weather:
    enabled: false
    # API key loaded from OPENWEATHER_API_KEY env var
    units: "metric"
    provider: "wttr"  # "wttr" (free, default) or "openweather" (requires API key)

  goldapi:
    enabled: false
    # API key loaded from GOLDAPI_KEY or GOLD_API_KEY env var

  calendar:
    enabled: false
    provider: "google"

  github:
    enabled: false
    # Token loaded from GITHUB_TOKEN env var

  notion:
    enabled: false
    # API key loaded from NOTION_API_KEY env var

# Provider Credentials (optional; env vars still supported)
providers:
  openai:
    api_key: null
    access_token: null
    base_url: null
  anthropic:
    api_key: null
    access_token: null
    base_url: null
  ollama_cloud:
    base_url: null
    api_key: null
  chutes:
    api_key: null  # Set CHUTES_API_KEY env var or provide here
    base_url: null  # Default: https://llm.chutes.ai/v1
    models:
      default: "Qwen/Qwen3-32B"
      reasoning: "deepseek-ai/DeepSeek-V3"
      deep: "moonshotai/Kimi-K2.5-TEE"  # For complex/deep reasoning
      vision: "Qwen/Qwen2.5-VL-72B-Instruct"
      code: "Qwen/Qwen2.5-Coder-32B-Instruct"
      fast: "unsloth/gemma-3-4b-it"
      balanced: "Qwen/Qwen3-32B"

# Safety Settings
safety:
  confirm_destructive: true
  log_all_commands: true
  max_shell_timeout: 30
  allowed_directories:
    - "~"
    - "/tmp"
  blocked_commands:
    - "rm -rf"
    - "sudo"
    - "mkfs"

# Voice Settings (future)
voice:
  enabled: false
  stt_model: "whisper"
  tts_engine: "say"
  wake_word: "jarvis"

# Logging
logging:
  level: "INFO"
  file: "logs/jarvis.log"
  max_size_mb: 10
  backup_count: 3
